---
layout: post
title:  "Building makemore Part2: MLP"
date:   2024-09-30 12:00:00 +0900
categories: [LLM]
tags: [DeepLearning , MLP , ]
math: true
---
# Building makemore Part2: MLP

## link

https://www.youtube.com/watch?v=TCH_1BHY58I


## intro

bigram은 단순한 신경명(단일 선형층) 을 사용해서 만들었다. 이 모델의 한계는 한 문자의 이전 문맥(컨텍스트)만 고려하여 예측의 품질이 좋지 않다.
이때, 더 긴 텍스트를 사용할 때 문제점이 나타난다

예: 2문자 컨텍스트 = 729(27*27)가지, 3문자 컨텍스트 = 20,000(27*27*27)가지

따라서, MLP 모델을 도입하여 다음 문자 예측에 사용할 것이다. 

## Bengio et al. 2003 (MLP language model) paper walkthrough

### 1. 논문 소개
- 이 논문은 다층 퍼셉트론(MLP)을 사용한 언어 모델링에 관한 중요한 연구임
- 최초의 논문은 아니지만, 이 분야에서 매우 영향력 있는 논문으로 자주 인용됨
- 19페이지 분량으로, 상세하고 읽기 쉬운 내용을 담고 있음

### 2. 이전 강의와의 연결
- 이전 강의에서 다룬 bigram 모델의 한계를 극복하기 위한 접근법
- bigram 모델은 한 문자의 이전 컨텍스트만 고려하여 예측 품질이 낮았음

### 3. 모델 구조
- **어휘 크기**: 17,000개 단어 (논문 기준)
- **임베딩**: 
  - 각 단어를 30차원 벡터로 표현
  - 17,000개의 점이 30차원 공간에 분포
- **입력**: 이전 3개 단어
- **은닉층**: 크기는 하이퍼파라미터 (예: 100 뉴런)
- **출력층**: 17,000개 뉴런 (다음 단어 예측)

### 4. 임베딩 공간의 특성
- 초기에는 랜덤하게 분포
- 학습을 통해 의미적으로 유사한 단어들이 가까워짐
- 예: 'a'와 'the'가 서로 가까운 위치에 있을 수 있음

### 5. 학습 방법
- 다층 신경망 사용
- 로그 우도 최대화 (이전 강의의 bigram 모델과 동일)
- 역전파를 통한 파라미터 최적화

### 6. 모델의 장점: 일반화 능력
- 예시: "a dog was running in a ___" 문장 예측
- 정확한 문구를 학습하지 않았더라도 유사한 문맥을 통해 예측 가능
- 임베딩 공간을 통한 지식 전이 (예: 'dog'와 'cat'의 유사성)

### 7. 신경망 구조 상세 설명
- **입력층**: 
  - 3개 단어, 각 30차원 → 총 90개 뉴런
  - 각 단어는 0에서 16,999 사이의 정수로 표현
- **임베딩 룩업 테이블 (C)**:
  - 17,000 x 30 크기의 행렬
  - 각 단어 인덱스에 해당하는 행을 추출하여 임베딩 벡터 생성
- **은닉층**:
  - 크기는 하이퍼파라미터 (예: 100 뉴런)
  - 입력층의 90개 뉴런과 완전 연결
- **출력층**: 
  - 17,000개 뉴런 (각 단어의 확률)
  - 은닉층과 완전 연결
- **소프트맥스 층**: 
  - 출력층의 로짓을 확률 분포로 변환

### 8. 파라미터 최적화
- 출력층 가중치와 편향
- 은닉층 가중치와 편향
- 임베딩 룩업 테이블 C
- 모든 파라미터는 역전파를 통해 동시에 최적화됨

## (re-)building our training dataset


### 1. 초기 설정

```python
import torch
import matplotlib.pyplot as plt

# 이름 목록 읽기
words = open('names.txt', 'r').read().splitlines()
print(words[:8])  # 처음 8개 이름 출력

# 문자 집합 생성 및 매핑
chars = sorted(list(set(''.join(words))))
stoi = {s:i+1 for i,s in enumerate(chars)}
stoi['.'] = 0
itos = {i:s for s,i in stoi.items()}
print(itos)
```

- PyTorch와 Matplotlib 라이브러리를 임포트합니다.
- 'names.txt' 파일에서 이름 목록을 읽어옵니다.
- 모든 이름에서 사용된 고유 문자를 추출하고 정렬합니다.
- 문자를 정수로 매핑하는 딕셔너리(stoi)와 그 역(itos)을 생성합니다.
- '.' 문자를 패딩으로 사용하며, 이를 0으로 매핑합니다.

### 2. 데이터셋 생성 함수

```python
# 데이터셋 구축

# 컨텍스트 길이 설정: 다음 문자를 예측하기 위해 사용할 이전 문자의 수
block_size = 3

# 입력(X)과 레이블(Y)을 저장할 리스트 초기화
X, Y = [], []

# 모든 단어에 대해 반복
for w in words[:5]:
    # 각 단어에 대한 초기 컨텍스트를 0(패딩)으로 설정
    context = [0] * block_size
    print(w)
    # 단어의 각 문자와 단어 끝을 나타내는 '.'에 대해 반복
    for ch in w + '.':
        # 현재 문자의 정수 인덱스를 가져옴
        ix = stoi[ch]
        
        # 현재 컨텍스트를 입력(X)에 추가
        X.append(context)
        
        # 현재 문자의 인덱스를 레이블(Y)에 추가
        Y.append(ix)
        
        #컨텍스트 업데이트: 가장 왼쪽(오래된) 문자를 제거하고 새 문자를 오른쪽에 추가
        context = context[1:] + [ix]

# 입력(X)을 PyTorch 텐서로 변환
X = torch.tensor(X)

# 레이블(Y)을 PyTorch 텐서로 변환
Y = torch.tensor(Y)
```

이 코드는 다음과 같은 작업을 수행합니다:

1. `block_size`로 컨텍스트 길이를 정의합니다. 여기서는 3으로 설정되어 있어, 3개의 이전 문자를 사용해 다음 문자를 예측합니다.

2. 모든 단어에 대해 반복하면서:
   - 각 단어의 시작에서 컨텍스트를 패딩(0)으로 초기화합니다.
   - 단어의 각 문자(그리고 단어의 끝을 나타내는 '.')에 대해:
     - 현재 문자의 정수 인덱스를 가져옵니다.
     - 현재 컨텍스트를 X에 추가합니다.
     - 현재 문자의 인덱스를 Y에 추가합니다.
     - 컨텍스트를 업데이트합니다 (가장 오래된 문자 제거, 새 문자 추가).

3. 최종적으로 X와 Y를 PyTorch 텐서로 변환합니다.

### 4. 데이터셋 특성
- 각 입력(X)은 3개의 정수로 구성됩니다 (block_size가 3이므로).
- 각 레이블(Y)은 예측해야 할 다음 문자의 정수 인덱스입니다.
- 패딩('.')은 0으로 표현됩니다.

### 5. 블록 크기 변경
- `block_size`를 변경하여 컨텍스트 길이를 조절할 수 있습니다.
- 예: `block_size = 4`로 설정하면 4개 문자로 5번째 문자를 예측합니다.
- `block_size = 10`으로 설정하면 10개 문자로 11번째 문자를 예측합니다.

### 6. 최종 데이터셋
- 5개 단어에서 32개의 예제가 생성됩니다.
- X: (32, 3) 형태의 텐서 (32개 예제, 각 3개의 정수)
- Y: (32,) 형태의 텐서 (32개의 레이블)


## implementing the embedding lookup table


### 1. 임베딩 테이블 초기화

```python
import torch

# 가능한 문자 수 (26개 알파벳 + '.')
num_chars = 27
# 임베딩 차원
embedding_dim = 2

# 임베딩 룩업 테이블을 랜덤하게 초기화
C = torch.randn((num_chars, embedding_dim))

print(C.shape, C)
```

### 2. 단일 정수 임베딩

```python
# 단일 정수 임베딩 (예: 5)
idx = 5
print(C[idx])
```

### 3. 원-핫 인코딩을 사용한 임베딩 (참고용)

```python
# 원-핫 인코딩 방식 (참고용)
one_hot = torch.nn.functional.one_hot(torch.tensor(5), num_classes=27).float() #float만 @연산 가능 int일 경우 안됨
print(one_hot @ C)
```

### 4. 다중 정수 동시 임베딩

```python
# 다중 정수 동시 임베딩
idx_list = [5, 6, 7]
print(C[idx_list])

# 텐서를 사용한 인덱싱
idx_tensor = torch.tensor([5, 6, 7])
print(C[idx_tensor])

# 반복 인덱싱
idx_repeat = torch.tensor([7, 7, 7])
print(C[idx_repeat])
```

### 5. 다차원 텐서 임베딩

```python
# 2차원 텐서 임베딩
X = torch.randint(0, 27, (32, 3))  # (32, 3) 크기의 랜덤 정수 텐서
emb = C[X]  # (32, 3, 2) 크기의 임베딩 결과

print(emb.shape)
print(emb[13, 2])  # 13번째 예제의 3번째 문자 임베딩
print(C[X[13, 2]])  # 동일한 결과 확인
```

### 주요 설명 포인트:

1. `C`는 (27, 2) 형태의 임베딩 룩업 테이블입니다.
2. 단일 정수 임베딩은 간단히 `C[idx]`로 수행됩니다.
3. 원-핫 인코딩 방식은 참고용으로 제시되었으며, 실제로는 사용하지 않습니다.
4. PyTorch의 유연한 인덱싱 기능을 사용하여 리스트, 텐서, 다차원 텐서로 동시에 여러 임베딩을 검색할 수 있습니다.
5. `X`가 (32, 3) 형태의 입력 텐서일 때, `C[X]`는 (32, 3, 2) 형태의 임베딩 결과를 생성합니다.

## implementing the hidden layer + internals of torch.Tensor: storage, views

### 1. 은닉층 구현

```python
# 임베딩 룩업 테이블 C와 입력 X가 이미 정의되어 있다고 가정
emb = C[X]  # (32, 3, 2) 형태의 임베딩 결과

# 은닉층 가중치와 편향 초기화
W1 = torch.randn((6, 100))  # 6 = 3 * 2 (block_size * embedding_dim)
b1 = torch.randn(100)

# 입력 재구성 방법 1: torch.cat 사용 (비효율적)
# x = torch.cat([emb[:, 0, :], emb[:, 1, :], emb[:, 2, :]], dim=1)

# 입력 재구성 방법 2: torch.unbind 사용
# x = torch.cat(torch.unbind(emb, dim=1), dim=1)

# 입력 재구성 방법 3: view 사용 (가장 효율적)
x = emb.view(emb.shape[0], -1)  # (32, 6) 형태로 변환

# 은닉층 계산
h = torch.tanh(x @ W1 + b1)  # (32, 100) 형태의 은닉층 출력

print(h.shape)  # 출력: torch.Size([32, 100])
```

### 2. torch.Tensor의 내부 구조: Storage와 Views

```python
# 1차원 텐서 생성
a = torch.arange(18)
print(a.shape)  # 출력: torch.Size([18])

# 다양한 view 생성
b = a.view(2, 9)
c = a.view(9, 2)
d = a.view(3, 3, 2)

print(b.shape)  # 출력: torch.Size([2, 9])
print(c.shape)  # 출력: torch.Size([9, 2])
print(d.shape)  # 출력: torch.Size([3, 3, 2])

# 모든 view가 동일한 데이터를 공유함을 확인
a[0] = 100
print(b[0, 0])  # 출력: 100
print(c[0, 0])  # 출력: 100
print(d[0, 0, 0])  # 출력: 100
```

### 주요 포인트 및 설명:

1. **입력 재구성 방법들**:
   - `torch.cat`: 각 임베딩을 개별적으로 추출하고 연결합니다. 새로운 메모리를 할당하므로 비효율적입니다.
   - `torch.unbind`: 텐서를 지정된 차원을 따라 분리합니다. `cat`보다 더 일반적이지만 여전히 새 메모리를 할당합니다.
   - `view`: 가장 효율적인 방법. 새로운 메모리 할당 없이 텐서의 형상을 변경합니다.

2. **torch.Tensor의 내부 구조**:
   - 텐서의 실제 데이터는 1차원 배열인 'storage'에 저장됩니다.
   - `view` 메서드는 storage offset, strides, shapes를 조작하여 텐서의 형상을 변경합니다.
   - 다양한 view들은 동일한 underlying storage를 공유합니다.

3. **브로드캐스팅**:
   - `x @ W1 + b1`에서 b1은 자동으로 모든 배치 예제에 대해 브로드캐스팅됩니다.
   - 브로드캐스팅은 오른쪽에서 왼쪽으로 정렬되며, 필요한 경우 새로운 차원이 추가됩니다.

4. **효율성**:
   - `view`를 사용한 재구성은 메모리 효율적입니다.
   - `torch.cat`과 같은 연산은 새로운 메모리를 할당하므로 덜 효율적입니다.

5. **유연성**:
   - `emb.view(emb.shape, -1)`에서 `-1`을 사용하여 PyTorch가 자동으로 차원을 추론하도록 할 수 있습니다.


## implementing the output layer

### 1. 출력층 가중치와 편향 초기화
```python
W2 = torch.randn((100, 27))  # 100: 은닉층 크기, 27: 가능한 문자 수
b2 = torch.randn(27)
```
- 은닉층의 출력(100)을 27개의 가능한 문자로 매핑합니다.

### 2. 로짓 계산
```python
logits = h @ W2 + b2  # 형상: (32, 27)
```
- `h`: 은닉층의 출력 (32, 100)
- 행렬 곱셈 후 편향을 더해 로짓을 계산합니다.

### 3. 확률 계산 (소프트맥스 구현)
```python
counts = torch.exp(logits)
probs = counts / counts.sum(dim=1, keepdim=True)
```
- 이전 강의의 비그램 모델과 동일한 방식으로 소프트맥스를 구현합니다.
- `exp`로 로짓을 지수화하고, 각 행별로 정규화하여 확률 분포를 생성합니다.

### 4. 형상 및 정규화 확인
```python
print(logits.shape)  # 출력: torch.Size([32, 27])
print(probs.shape)   # 출력: torch.Size([32, 27])
print(probs.sum(dim=1))  # 각 행의 합이 1인지 확인
```
- 로짓과 확률의 형상이 예상대로인지 확인합니다.
- 각 행의 합이 1인지 확인하여 올바른 확률 분포인지 검증합니다.

### 주요 포인트:
1. 출력층은 은닉층의 출력을 받아 각 문자의 확률을 계산합니다.
2. 소프트맥스 함수는 로짓을 확률로 변환합니다.
3. PyTorch의 브로드캐스팅 기능이 편향 더하기에 자동으로 적용됩니다.
4. 이 구현은 이전 강의의 비그램 모델을 확장한 것입니다.



## implementing the negative log likelihood loss

```python
# 로짓을 지수화하여 counts 얻기
counts = torch.exp(logits)

# counts를 정규화하여 확률 분포 얻기
# dim=1: 각 행(예제)에 대해 정규화
# keepdim=True: 결과의 차원을 유지
probs = counts / counts.sum(dim=1, keepdim=True)

# 확률 분포의 형태 확인
print(probs.shape)  # 출력: torch.Size([32, 27])

# 각 행의 합이 1인지 확인 (정규화 검증)
print(probs.sum(dim=1))

# 정답 문자의 확률 추출
# torch.arange(32): 0부터 31까지의 배치 인덱스
# Y: 각 예제의 정답 문자 인덱스
correct_probs = probs[torch.arange(32), Y]

# 추출된 확률 출력
print(correct_probs)

# Negative Log Likelihood 손실 계산
# torch.log(): 자연로그 계산
# .mean(): 평균 계산
loss = -torch.log(correct_probs).mean()

# 최종 손실 출력
print(f"Loss: {loss.item():.4f}")
```

주석 설명:

1. `counts = torch.exp(logits)`: 로짓을 지수화하여 'fake counts'를 생성합니다. 이는 소프트맥스 함수의 첫 단계입니다.

2. `probs = counts / counts.sum(dim=1, keepdim=True)`: 
   - 각 예제(행)에 대해 counts를 정규화하여 확률 분포를 얻습니다.
   - `dim=1`은 각 행에 대해 연산을 수행함을 의미합니다.
   - `keepdim=True`는 결과의 차원을 유지하여 브로드캐스팅이 올바르게 작동하도록 합니다.

3. `print(probs.shape)`: 확률 분포의 형태를 확인합니다. [32, 27]은 32개의 예제 각각에 대해 27개 문자의 확률을 나타냅니다.

4. `print(probs.sum(dim=1))`: 각 예제(행)의 확률 합이 1인지 확인하여 올바르게 정규화되었는지 검증합니다.

5. `correct_probs = probs[torch.arange(32), Y]`:
   - 각 예제에 대해 정답 문자의 예측 확률을 추출합니다.
   - `torch.arange(32)`는 배치 내 각 예제의 인덱스(0부터 31까지)를 생성합니다.
   - `Y`는 각 예제의 정답 문자 인덱스입니다.

6. `loss = -torch.log(correct_probs).mean()`:
   - 정답 확률의 로그를 취하고, 그 평균의 음수를 계산하여 손실을 구합니다.
   - 이는 Negative Log Likelihood 손실 함수의 구현입니다.

7. `print(f"Loss: {loss.item():.4f}")`: 계산된 손실 값을 소수점 4자리까지 출력합니다.

이 구현은 신경망의 예측을 평가하고, 학습 신호를 제공하는 핵심 부분입니다. 손실 값이 낮을수록 모델의 예측이 정확함을 의미합니다.




## Summary of the Full Network

```python
# 데이터셋 형태 확인
print(Xtr.shape, Ytr.shape)  # 데이터셋 크기 출력

# 재현성을 위한 랜덤 시드 설정
g = torch.Generator().manual_seed(2147483647)

# 파라미터 초기화
C = torch.randn((27, 10), generator=g)  # 문자 임베딩
W1 = torch.randn((30, 200), generator=g)  # 첫 번째 가중치 행렬
b1 = torch.randn(200, generator=g)  # 첫 번째 편향
W2 = torch.randn((200, 27), generator=g)  # 두 번째 가중치 행렬
b2 = torch.randn(27, generator=g)  # 두 번째 편향

# 모든 파라미터를 하나의 리스트로 모음
parameters = [C, W1, b1, W2, b2]

# 총 파라미터 수 계산
print(sum(p.nelement() for p in parameters))  # 총 파라미터 수 출력

# Forward pass
emb = C[X]  # (32, 3, 10)
hidden = torch.tanh(emb.view(-1, 30) @ W1 + b1)  # (32, 200)
logits = hidden @ W2 + b2  # (32, 27)
#counts = logits.exp()
#prob = counts/ counts.sum(1,keepdims = True)
#loss = -prob(torch.arrange(32,Y)).log().mean()
loss = F.cross_entropy(logits, Y)
```

주요 포인트:
1. `Xtr.shape, Ytr.shape`를 출력하여 데이터셋의 크기를 확인합니다.
2. `torch.Generator().manual_seed(2147483647)`를 사용하여 재현 가능한 결과를 위해 랜덤 시드를 설정합니다.
3. 각 파라미터(C, W1, b1, W2, b2)를 랜덤으로 초기화합니다.
4. `parameters` 리스트에 모든 파라미터를 모아 관리합니다.
5. `sum(p.nelement() for p in parameters)`로 총 파라미터 수를 계산합니다.
6. Forward pass는 이전과 동일하게 구현됩니다.

이 코드는 신경망의 초기 설정과 파라미터 초기화를 보여줍니다. 재현성을 위해 랜덤 시드를 사용하고, 각 파라미터의 크기와 초기화 방법을 명확히 보여줍니다. 또한 총 파라미터 수를 계산하여 모델의 복잡도를 파악할 수 있게 합니다.

## Introducing F.cross_entropy and Why


```python
# 이전 구현 (교육 목적)
counts = torch.exp(logits)
probs = counts / counts.sum(1, keepdim=True)
loss = -torch.log(probs[torch.arange(32), Y]).mean()

# F.cross_entropy 사용 (실제 사용)
loss = F.cross_entropy(logits, Y)
```

`F.cross_entropy` 사용 이유:

1. 효율성:
   - 중간 텐서(counts, probs)를 생성하지 않아 메모리 효율적입니다.
   - PyTorch가 연산을 최적화된 커널로 융합하여 실행 속도가 빠릅니다.

2. 수치적 안정성:
   - 내부적으로 로짓의 최대값을 빼서 오버플로우를 방지합니다.
   ```python
   # 예: 극단적인 로짓 값
   logits = torch.tensor([-100, 100])
   # F.cross_entropy는 내부적으로 최대값(100)을 빼서 계산
   # 결과: tensor([0, -200])  # 안정적인 계산
   ```

3. 역전파 효율성:
   - 수학적으로 단순화된 그래디언트 계산으로 역전파가 더 효율적입니다.

4. 코드 간결성:
   - 한 줄로 손실 계산이 가능하여 코드가 간결해집니다.

주의사항:
- `F.cross_entropy`는 로짓을 입력으로 받으며, 내부적으로 소프트맥스를 적용합니다.
- 타겟(Y)은 정수 인덱스 형태여야 합니다.

이 정리는 전체 신경망 구조의 개요와 `F.cross_entropy` 함수 사용의 이점을 설명합니다. 코드와 설명을 통해 실제 구현 방식과 그 이유를 이해할 수 있도록 구성했습니다.


## Implementing the Training Loop, Overfitting One Batch



1. 초기 설정:
     ```python
     #손실 함수 설정
     emb = C[X]  # (32, 3, 10)
     hidden = torch.tanh(emb.view(-1, 30) @ W1 + b1)  # (32, 200)
     logits = hidden @ W2 + b2  # (32, 27)
     loss = F.cross_entropy(logits, y)
     ```
     ```python
     #파라미터 최적화 설정
     for p in parameters:
     p.requires_grad = True
     ```
     ```python
     #파라미터 그래디언트 초기화
     for p in parameters:
         p.grad = None
     ```
     ```python
     파라미터 update 설정
     loss.backward()
     for p in parameters:
         p.data += -0.1 * p.grad #-0.1은 leanring_rate이다.
     ```

2. 학습 루프 구현:
   ```python
   for _ in range(1000):  # 1000번 반복
       # 순전파
       logits = model(x)
       loss = F.cross_entropy(logits, y)
       print(loss.item())  # 손실 출력 전부다 -> 마지막만 알고 싶으면 맨 밑으로
       # 역전파
       for p in parameters:
           p.grad = None
       loss.backward()
       
       # 파라미터 업데이트
       for p in parameters:
           p.data -= learning_rate * p.grad
       
   ``` 

3. 미니배치 사용:
   ```python
   batch_size = 32
   ix = torch.randint(0, x.shape[0], (batch_size,))
   xb, yb = x[ix], y[ix]
   ```

4. 과적합 현상 관찰:
   - 32개 샘플에 대해 1000번 반복 학습 시 손실이 17에서 매우 낮은 값으로 감소
   - 3400개 파라미터로 32개 샘플을 쉽게 과적합시킴

5. 완벽한 과적합 불가능 이유 분석:
   ```python
   logits = model(x)
   _, predicted = logits.max(1)
   print(predicted)
   print(y)
   ```
   - 예측값과 실제값 비교를 통해 동일 입력에 대한 다중 출력 가능성 확인

6. 전체 데이터셋 사용:
   ```python
   words = open('input.txt', 'r').read().splitlines()
   chars = sorted(list(set(''.join(words))))
   stoi = {s:i for i,s in enumerate(chars)}
   itos = {i:s for s,i in stoi.items()}
   
   block_size = 3
   X, Y = [], []
   for w in words:
       context = [0] * block_size
       for ch in w + '.':
           ix = stoi[ch]
           X.append(context)
           Y.append(ix)
           context = context[1:] + [ix]
   
   X = torch.tensor(X)
   Y = torch.tensor(Y)
   ```

7. 미니배치 최적화:
   ```python
   batch_size = 32
   for _ in range(10000):
       ix = torch.randint(0, X.shape[0], (batch_size,))
       Xb, Yb = X[ix], Y[ix]
       
       # 순전파
       logits = model(Xb)
       loss = F.cross_entropy(logits, Yb)
       
       # 역전파
       for p in parameters:
           p.grad = None
       loss.backward()
       
       # 파라미터 업데이트
       for p in parameters:
           p.data -= 0.1 * p.grad
   ```

8. 학습 진행 상황 모니터링:
   ```python
   @torch.no_grad()
   def estimate_loss():
       out = {}
       model.eval()
       for split in ['train', 'val']:
           losses = torch.zeros(eval_iters)
           for k in range(eval_iters):
               X, Y = dataset[split]
               logits = model(X)
               loss = F.cross_entropy(logits, Y)
               losses[k] = loss.item()
           out[split] = losses.mean()
       model.train()
       return out

   print(estimate_loss())
   ```

## training on the full dataset, minibatches


1. 전체 데이터셋 처리:
   ```python
   # 데이터셋 구축

   # 컨텍스트 길이 설정: 다음 문자를 예측하기 위해 사용할 이전 문자의 수
   block_size = 3

   # 입력(X)과 레이블(Y)을 저장할 리스트 초기화
   X, Y = [], []

   # 모든 단어에 대해 반복
   for w in words:
      # 각 단어에 대한 초기 컨텍스트를 0(패딩)으로 설정
      context = [0] * block_size
      print(w)
      # 단어의 각 문자와 단어 끝을 나타내는 '.'에 대해 반복
      for ch in w + '.':
         # 현재 문자의 정수 인덱스를 가져옴
         ix = stoi[ch]
         
         # 현재 컨텍스트를 입력(X)에 추가
         X.append(context)
         
         # 현재 문자의 인덱스를 레이블(Y)에 추가
         Y.append(ix)
         
         #컨텍스트 업데이트: 가장 왼쪽(오래된) 문자를 제거하고 새 문자를 오른쪽에 추가
         context = context[1:] + [ix]

   # 입력(X)을 PyTorch 텐서로 변환
   X = torch.tensor(X)

   # 레이블(Y)을 PyTorch 텐서로 변환
   Y = torch.tensor(Y)
   ```
   - 전체 데이터셋 처리 결과 228,000개의 예제 생성

2. 가중치 재초기화 및 그래디언트 설정:
   ```python
   # 재현성을 위한 랜덤 시드 설정
   g = torch.Generator().manual_seed(2147483647)

   # 파라미터 초기화
   C = torch.randn((27, 10), generator=g)  # 문자 임베딩
   W1 = torch.randn((30, 200), generator=g)  # 첫 번째 가중치 행렬
   b1 = torch.randn(200, generator=g)  # 첫 번째 편향
   W2 = torch.randn((200, 27), generator=g)  # 두 번째 가중치 행렬
   b2 = torch.randn(27, generator=g)  # 두 번째 편향

   # 모든 파라미터를 하나의 리스트로 모음
   parameters = [C, W1, b1, W2, b2]

   # 그래디언트 설정
   for p in parameters:
       p.requires_grad = True
   ```

3. 최적화  :
   ```python
     for _ in range(10)
        #미니배치 construct    #
         ix =torch.randint(0,X.shape[0],(32,) ) #배치크기 맞추기 -> 200만에서 (32,200으로 바꾸기)
        #손실 함수 설정
         emb = C[X[ix]]  # (32, 3, 2)  
         hidden = torch.tanh(emb.view(-1, 30) @ W1 + b1)  # (32, 200)
         logits = hidden @ W2 + b2  # (32, 27)
         loss = F.cross_entropy(logits, Y[ix])
         print(loss.item())
         #미니배치 construct    #
         ix =torch.randint(0,X.shape[0],(32,) )

         #파라미터 최적화 설정
         for p in parameters:
         p.requires_grad = True


         #파라미터 그래디언트 초기화
         for p in parameters:
               p.grad = None

         #파라미터 update 설정
         loss.backward()
         for p in parameters:
               p.data += -0.1 * p.grad #-0.1은 leanring_rate이다.
     ```

    -이는 미니 배치에 대한 손실일 뿐이기에 전체 데이터셋에 대한 손실 평가가 필요하다 

4. 전체 데이터셋에 대한 손실 평가
   ```python
         emb = C[X]  # (32, 3, 2)  
         hidden = torch.tanh(emb.view(-1, 30) @ W1 + b1)  # (32, 200)
         logits = hidden @ W2 + b2  # (32, 27)
         loss = F.cross_entropy(logits, Y)
         loss
   ```


주요 포인트:
1. 전체 데이터셋을 사용하면 계산 시간이 크게 증가합니다.
2. 미니배치 최적화를 통해 학습 속도를 크게 향상시킬 수 있습니다.
3. 미니배치를 사용하면 그래디언트의 품질이 낮아지지만, 더 많은 학습 단계를 수행할 수 있어 전체적으로 더 효율적입니다.
4. 적절한 학습률을 결정하기 위해 여러 학습률을 시도하고 손실 변화를 관찰하는 방법을 사용할 수 있습니다.
이 과정을 통해 대규모 데이터셋에 대한 효율적인 학습 방법과 학습률 조정 기법을 배울 수 있습니다.

## finding a good initial learning rate


### 학습률 탐색 코드

1. **파라미터 초기화 및 학습률 범위 설정**:
   ```python
   import torch
   import matplotlib.pyplot as plt

   # 파라미터 초기화
   parameters = [torch.randn(10, requires_grad=True) for _ in range(5)]

   # 학습률 지수 설정
   lre = torch.linspace(-3, 0, 100)
   lrs = 10**lre
   ```

2. **학습률 탐색 루프**:
   - 각 학습률에 대해 손실을 계산하고 기록합니다.
   ```python
   lr= []
   lossi= []
     for _ in range(1000)
        #미니배치 construct    #
         ix =torch.randint(0,X.shape[0],(32,) ) #배치크기 맞추기 -> 200만에서 (32,200으로 바꾸기)
        #손실 함수 설정
         emb = C[X[ix]]  # (32, 3, 2)  
         hidden = torch.tanh(emb.view(-1, 30) @ W1 + b1)  # (32, 200)
         logits = hidden @ W2 + b2  # (32, 27)
         loss = F.cross_entropy(logits, Y[ix])
         print(loss.item())
         #미니배치 construct    #
         ix =torch.randint(0,X.shape[0],(32,) )

         #파라미터 최적화 설정
         for p in parameters:
         p.requires_grad = True


         #파라미터 그래디언트 초기화
         for p in parameters:
               p.grad = None

         #파라미터 update 설정
         lr = lrs[i]
         loss.backward()
         for p in parameters:
               p.data += -lr * p.grad #-0.1은 leanring_rate이다.
         # track stats
         lri.append(lr)
         lossi.append(loss.item())
     ```

3. **손실과 학습률의 그래프 그리기**:
   - 손실과 학습률을 시각적으로 비교하여 최적의 학습률을 찾습니다.
   ```python
   plt.plot(lri, lossis)
   plt.xlabel('Learning Rate Exponent')
   plt.ylabel('Loss')
   plt.title('Learning Rate vs Loss')
   plt.show()

   ```

### 요약

- **적절한 학습률**은 손실이 가장 빠르게 감소하는 구간에서 결정됩니다.
- **지수적 증가**를 통해 다양한 학습률을 시도하여 최적의 값을 찾습니다.
- **그래프 분석**을 통해 최적의 학습률을 시각적으로 확인할 수 있습니다.




## splitting up the dataset into train/val/test splits and why

### 데이터셋 분할의 중요성

1. **과적합 방지**:
   - 모델이 훈련 데이터에만 맞춰져 새로운 데이터에 일반화되지 않는 문제를 방지하기 위해 데이터셋을 분할합니다.
   - 훈련, 검증, 테스트 세트를 사용하여 모델의 일반화 성능을 평가할 수 있습니다.

2. **데이터셋 분할 방법**:
   - **훈련 세트 (Train Set)**: 전체 데이터의 80%로 모델의 파라미터를 학습합니다.
   - **검증 세트 (Validation Set)**: 전체 데이터의 10%로 하이퍼파라미터 튜닝에 사용합니다.
   - **테스트 세트 (Test Set)**: 전체 데이터의 10%로 최종 모델 성능을 평가합니다.

3. **코드 구현**:
   - 데이터를 무작위로 섞고, 각 세트에 할당합니다.
   ```python
   import random

   # 데이터 무작위 셔플
   random.seed(42)
   random.shuffle(words)

   # 데이터셋 분할 인덱스 계산
   n1 = int(len(words) * 0.8)
   n2 = int(len(words) * 0.9)

   # 데이터셋 분할
   train_words = words[:n1]
   val_words = words[n1:n2]
   test_words = words[n2:]

   # 배열 생성 함수
   def build_dataset(words):
      block_size = 3
       X, Y = [], []
       for w in words:
           context = [0] * block_size
           for ch in w + '.':
               ix = stoi[ch]
               X.append(context)
               Y.append(ix)
               context = context[1:] + [ix]
       return torch.tensor(X), torch.tensor(Y)

   # 각 세트에 대해 배열 생성
   X_train, Y_train = build_dataset(words[:n1])
   X_val, Y_val = build_dataset(words[n1:n2])
   X_test, Y_test = build_dataset(words[n2:])
   ```

4. **모델 평가**:
   - 훈련 중에는 검증 세트를 사용하여 모델이 과적합되지 않도록 조정합니다.
   - 테스트 세트는 최종 성능 평가에만 사용하여 모델이 잘 일반화되는지 확인합니다.


## Experiment: Larger Hidden Layer

### 실험 목표

- **모델 용량 증가**: 신경망의 숨겨진 레이어 크기를 증가시켜 모델 성능을 향상시키는 것을 목표로 합니다.

### 코드 구현

1. **신경망 초기화**:
   - 숨겨진 레이어의 뉴런 수를 100에서 300으로 증가시킵니다.
   ```python
      g = torch.Generator().manual_seed(2147483647) # for reproducibility
      C = torch.randn((27, 2), generator=g)
      W1 = torch.randn((6, 300), generator=g)
      b1 = torch.randn(300, generator=g)
      W2 = torch.randn((300, 27), generator=g)
      b2 = torch.randn(27, generator=g)
      parameters = [C, W1, b1, W2, b2]
   ```

2. **훈련 및 손실 추적**:
   - 손실과 학습 단계를 추적하여 그래프로 시각화합니다.
   ```python
   lri = []
   lossi = []
   stepi = []

   for i in range(30000):
       # 순전파
       ix = torch.randint(0,Xtr.shaep[0],[32,])
       emb = C[Xtr[ix]] #(32,3,2)
       h= torch.tanh(emb.view(-1,6) @ W1 + b1) #(32,100)
       logits = h @ W2 + b2 #(32,27)
       loss = F.cross_entropy(logits, Ytr[ix])

       # 역전파 및 파라미터 업데이트
       for p in parameters:
         p.grad = None
         loss.backward()
       lr = 0.01
       for p in parameters:
         p.data +=lr *p.grad

       # 손실 기록
       lri.append(lre[i])
       stepi.append(i)
       lossi.append(loss.item())
   ```
   
   ``` python
   #시각화
   plt.plot(stepi,lossi)
   ```
   
3. **결과 분석**:
   - 모델의 크기가 커지면서 학습 시간이 증가할 수 있으며, 적절한 학습률 조정이 필요합니다.
   - 배치 크기를 조정하여 그래디언트의 노이즈를 줄일 수 있습니다.

4. **임베딩 시각화**:
   - 2차원 임베딩을 시각화하여 문자 간의 관계를 확인합니다.

   ```python
   plt.figure(figsize=(8,8))
   plt.scatter(C[:,0].data, C[:,1].data, s=200)
   for i in range(C.shape[0]):
      plt.text(C[i,0].item(), C[i,1].item(), itos[i], ha="center", va="center", color='white')
   plt.grid('minor')
   ```

### 요약

- **모델 확장**: 숨겨진 레이어를 확장하여 모델의 표현력을 높였습니다.
- **학습률 및 배치 크기 조정**: 더 큰 모델에 맞게 학습률과 배치 크기를 조정하여 안정적인 학습을 도모했습니다.
- **임베딩 시각화**: 학습된 문자 임베딩을 시각화하여 모델이 문자를 어떻게 구분하는지 확인했습니다.

이 실험은 신경망의 구조를 변경하여 성능을 최적화하는 방법을 탐구합니다.

## title="visualizing the character embeddings"

### 실험 목표

- **임베딩 시각화**: 신경망이 학습한 문자 임베딩을 시각화하여 문자 간의 관계를 이해합니다.
- **임베딩 크기 증가**: 임베딩 크기를 늘려 모델의 성능을 향상시키고자 합니다.

### 코드 구현

1. **임베딩 시각화**:
   - 2차원 임베딩을 시각화하여 각 문자의 위치와 클러스터링을 확인합니다.
   ```python
   import matplotlib.pyplot as plt
   ```

   ```python
   # 임베딩 시각화
   plt.figure(figsize=(8,8))
   plt.scatter(C[:,0].data, C[:,1].data, s=200)
   for i in range(C.shape[0]):
      plt.text(C[i,0].item(), C[i,1].item(), itos[i], ha="center", va="center", color='white')
   plt.grid('minor')
   ```

2. **임베딩 크기 증가**:
   - 임베딩 차원을 2에서 10으로 증가시켜 더 많은 정보를 캡처할 수 있도록 합니다.

   ```python
   embedding_size = 10
   C = torch.randn((vocab_size, embedding_size))

   # 입력 크기 변경
   input_size = embedding_size * block_size
   W1 = torch.randn((input_size, hidden_size))
   ```

3. **결과 분석**:
   - 모음이 클러스터링되는 등 네트워크가 문자를 유사하게 처리함을 확인합니다.
   - 임베딩 차원을 늘려 더 복잡한 관계를 모델링할 수 있습니다.

### 요약

- **임베딩 시각화**를 통해 신경망이 문자를 어떻게 구분하는지 확인할 수 있습니다.
- **임베딩 크기 증가**는 모델의 성능 향상에 기여할 수 있으며, 더 많은 차원을 사용하여 복잡한 패턴을 학습할 수 있습니다.

   ```python
      g = torch.Generator().manual_seed(2147483647) # for reproducibility
      C = torch.randn((27, 2), generator=g)
      W1 = torch.randn((6, 300), generator=g)
      b1 = torch.randn(300, generator=g)
      W2 = torch.randn((300, 27), generator=g)
      b2 = torch.randn(27, generator=g)
      parameters = [C, W1, b1, W2, b2]
   ```
## experiment: larger embedding size


### 실험 목표

- **임베딩 크기 증가**: 임베딩 차원을 늘려 모델의 성능을 향상시키고자 합니다.

### 코드 구현

1. **임베딩 크기 증가**:
   - 임베딩 차원을 2에서 10으로 증가시켜 더 많은 정보를 캡처할 수 있도록 합니다.

   ```python
      g = torch.Generator().manual_seed(2147483647) # for reproducibility
      C = torch.randn((27, 2), generator=g)
      W1 = torch.randn((30, 200), generator=g) #6에서 30으로 변환 
      b1 = torch.randn(200, generator=g)
      W2 = torch.randn((200, 27), generator=g)
      b2 = torch.randn(27, generator=g)
      parameters = [C, W1, b1, W2, b2]
   ```

2.  **훈련 및 손실 추적**:
   - 학습률을 조정하고 손실을 기록합니다
   ``` python
   lri = []
   lossi = []
   stepi = []
   for i in range(200000):
   
   # minibatch construct
   ix = torch.randint(0, Xtr.shape[0], (32,))
   
   # forward pass
   emb = C[Xtr[ix]] # (32, 3, 10)
   h = torch.tanh(emb.view(-1, 30) @ W1 + b1) # (32, 200)  #d여기 뒤에 30으로 바뀌는이유는??
   logits = h @ W2 + b2 # (32, 27)
   loss = F.cross_entropy(logits, Ytr[ix])
   #print(loss.item())
   
   # backward pass
   for p in parameters:
      p.grad = None
   loss.backward()
   
   # update
   #lr = lrs[i]
   lr = 0.1 if i < 100000 else 0.01
   for p in parameters:
      p.data += -lr * p.grad

   # track stats
   #lri.append(lre[i])
   stepi.append(i)
   lossi.append(loss.log10().item())

   ```

3. **손실 시각화**:
   - 손실을 로그 스케일로 시각화합니다.

   ```python
   plt.plot(stepi, lossi)
   ```

4. **결과 평가**:  
   - 훈련 및 검증 세트에서 손실 평가.

   ```python
   emb = C[Xtr] # (32, 3, 2)
   h = torch.tanh(emb.view(-1, 30) @ W1 + b1) # (32, 100)
   logits = h @ W2 + b2 # (32, 27)
   loss = F.cross_entropy(logits, Ytr)
   loss
   ```

   ```python
   emb = C[Xdev] # (32, 3, 2)
   h = torch.tanh(emb.view(-1, 30) @ W1 + b1) # (32, 100)
   logits = h @ W2 + b2 # (32, 27)
   loss = F.cross_entropy(logits, Ydev)
   loss
   ```


3. **결과 분석**:
   - 임베딩 크기를 늘려 모델의 표현력을 높이고, 학습이 더 잘 이루어지도록 합니다.
   - 학습률을 조정하여 최적의 성능을 달성합니다.

### 요약

- **임베딩 크기 증가**는 모델의 성능 향상에 기여하며 더 많은 차원을 사용하여 복잡한 패턴을 학습할 수 있습니다.
- **로그 스케일 시각화**를 통해 손실의 변화를 더 명확하게 관찰할 수 있습니다.


## Summary of Our Final Code and Conclusion

### 코드 요약

1. **모델 구성**:
   - 임베딩 차원을 10으로 설정하고, 숨겨진 레이어의 뉴런 수를 조정하여 모델의 용량을 확장했습니다.

2. **훈련 설정**:
   - 학습률을 0.1로 시작하여 100,000번의 반복 후 0.01로 감소시켰습니다.
   - 손실을 로그 스케일로 기록하여 시각화했습니다.

3. **결과 분석**:
   - 최상의 검증 손실은 2.17로 기록되었습니다.
   - 다양한 하이퍼파라미터 조정(예: 임베딩 크기, 숨겨진 레이어 크기, 배치 크기)을 통해 성능을 향상시킬 수 있습니다.

### 결론

- **모델 최적화**: 모델의 성능을 높이기 위해 여러 하이퍼파라미터를 실험해볼 수 있습니다.
- **추가 연구**: 관련 논문을 읽고 새로운 아이디어를 적용하여 모델을 개선할 수 있습니다.
- **샘플링**: 모델에서 샘플을 생성하는 방법도 고려할 수 있습니다.


## Sampling from the Model

### 과정 설명

1. **초기 설정**:
   - `context`를 모든 점으로 초기화합니다. 이는 모델이 시작할 초기 상태입니다.

2. **샘플링 루프**:
   - `while` 루프를 사용하여 모델이 문자를 생성할 때까지 반복합니다.

3. **임베딩 및 순전파**:
   - 현재 `context`를 임베딩 테이블 $ C $를 사용하여 임베딩합니다.
   - 임베딩된 벡터를 숨겨진 레이어로 전달하여 로짓을 계산합니다.

4. **확률 계산**:
   - `F.softmax`를 사용하여 로짓을 확률로 변환합니다.

5. **다음 문자 샘플링**:
   - `torch.multinomial`을 사용하여 확률 분포에서 다음 문자를 샘플링합니다.
   - 샘플링된 인덱스를 `context`에 추가하고, 출력 리스트에 기록합니다.

6. **종료 조건**:
   - 샘플링된 인덱스가 0일 경우, 루프를 종료합니다.

### 코드 구현

```python
import torch
import torch.nn.functional as F

# 샘플링 설정
g = torch.Generator().manual_seed(2147483647 + 10)

for _ in range(20):
    out = []
    context = [0] * block_size  # 초기 컨텍스트 설정
    while True:
        # 임베딩 및 순전파
        emb = C[torch.tensor([context])]  # (1, block_size, d)
        h = torch.tanh(emb.view(1, -1) @ W1 + b1)
        logits = h @ W2 + b2
        probs = F.softmax(logits, dim=1)

        # 다음 문자 샘플링
        ix = torch.multinomial(probs, num_samples=1, generator=g).item()
        context = context[1:] + [ix]
        out.append(ix)

        # 종료 조건
        if ix == 0:
            break

    # 출력 결과 처리 (예: 문자열 변환)
```

### 결과

- 생성된 샘플은 더 단어처럼 보이며, 모델의 성능을 확인할 수 있습니다.
- 이 방법을 통해 모델이 학습한 내용을 바탕으로 새로운 데이터를 생성할 수 있습니다.







